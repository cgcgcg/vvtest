#!/usr/bin/env python

# Copyright 2018 National Technology & Engineering Solutions of Sandia, LLC
# (NTESS). Under the terms of Contract DE-NA0003525 with NTESS, the U.S.
# Government retains certain rights in this software.

#RUNTEST:

import sys
sys.dont_write_bytecode = True
sys.excepthook = sys.__excepthook__
import os
import time
import glob

import vvtestutils as vtu
import testutils as util
from testutils import print3


class restart_tests( vtu.vvtestTestCase ):

    def test_that_notrun_or_notdone_get_run_upon_restart(self):
        ""
        util.writefile( "param.xml", """
            <rtest name="param">
              <parameterize hello="world mars"/>
              <execute>
                sleep 1
              </execute>
            </rtest>""" )
        util.writefile( "FailTest.xml", """
            <rtest name="FailTest">
              <execute>
                sleep 1
                exit 1
              </execute>
            </rtest>""")
        util.writefile( "DiffTest.xml", """
            <rtest name="DiffTest">
              <execute>
                sleep 1
                set have_diff = yes
              </execute>
            </rtest>""")
        time.sleep(1)

        # run the test set but provide a false interruption
        vtu.interrupt_vvtest_run( '-n 2', count=1 )
        vrun = vtu.runvvtest( '-i' )
        cntD = vtu.parse_vvtest_counts( vrun.out )
        assert cntD['total'] == 4 and cntD['notrun'] > 0

        # restart with no keywords
        vtu.runvvtest( '-n 2' )
        vtu.runvvtest( '-i' ).assertCounts( total=4, npass=2, diff=1, fail=1 )

        # restart using results keyword
        vtu.interrupt_vvtest_run( '-n 2 -w', count=1 )
        vrun = vtu.runvvtest( '-i' )
        cntD = vtu.parse_vvtest_counts( vrun.out )
        assert cntD['total'] == 4 and cntD['notrun'] > 0

        vtu.runvvtest( '-n 2 -k notrun/notdone' )
        vtu.runvvtest( '-i' ).assertCounts( total=4, npass=2, diff=1, fail=1 )

        # none should restart now
        vtu.runvvtest( '-n 2' ).assertCounts( total=0 )

        # all of them should run again
        vrun = vtu.runvvtest( '-n 2 -R' )
        vrun.assertCounts( total=4, npass=2, diff=1, fail=1 )

    def test_prerun_file_cleanout(self):
        ""
        util.writefile( "clean.xml", """
            <rtest name="clean">
              <execute> <![CDATA[
                foreach f ( `ls` )
                  echo "existing file = $f"
                end
                set noclobber
                echo "gen file contents" > generated_file.txt || exit 1
              ]]>
              </execute>
            </rtest>""" )
        time.sleep(1)

        for batch in [False,True]:

            vtu.remove_results()

            vrun = vtu.runvvtest( batch=batch )
            vrun.assertCounts( total=1, npass=1 )

            assert len( glob.glob( 'TestResults*/clean/generated_file.txt' ) ) == 1

            # the generated file should be removed prior to running the script
            vrun = vtu.runvvtest( '-R', batch=batch )
            vrun.assertCounts( total=1, npass=1 )
            assert vrun.countGrepLogs( 'existing*generated' ) == 0

            # with -m option should fail because of "noclobber" in script
            vrun = vtu.runvvtest( '-R -m', batch=batch )
            vrun.assertCounts( total=1, fail=1 )
            assert vrun.countGrepLogs( 'existing*generated' ) == 1

    def test_run_then_fix_a_test_then_restart(self):
        ""
        for batch in [False,True]:

            util.writefile( 'atest.xml', """
                <rtest name="atest">
                  <parameterize timestep="1 2"/>
                  <execute>
                    if ( "$timestep" == 2 ) then
                      echo "fake failure"
                      exit 1
                    else
                      touch atest.$timestep
                    endif
                  </execute>
                  <analyze>
                     ls ../atest.timestep=1/atest.1 || exit 1
                     ls ../atest.timestep=2/atest.2 || exit 1
                  </analyze>
                </rtest>""" )
            time.sleep(1)

            vtu.remove_results()

            vrun = vtu.runvvtest( batch=batch )
            vrun.assertCounts( total=3, npass=1, fail=1, notrun=1 )

            # "fix" the test and restart
            util.writefile( 'atest.xml', """
                <rtest name="atest">
                  <parameterize timestep="1 2"/>
                  <execute>
                    touch atest.$timestep
                  </execute>
                  <analyze>
                     ls ../atest.timestep=1/atest.1 || exit 1
                     ls ../atest.timestep=2/atest.2 || exit 1
                  </analyze>
                </rtest>""" )
            time.sleep(1)

            vrun = vtu.runvvtest( '-k fail/notrun', batch=batch )
            vrun.assertCounts( total=2, npass=2 )

    def test_restarting_script_tests(self):
        ""
        util.writefile( "param.vvt", """
            #!/usr/bin/env python
            #VVT: parameterize : hello = world mars
            import time
            time.sleep(1)
            """[1:] )
        util.writescript( "FailTest.vvt", """
            #!/usr/bin/env python
            import time
            time.sleep(1)
            raise Exception( "fake failure" )
            """ )
        util.writefile( "DiffTest.vvt", """
            #!/usr/bin/env python
            import vvtest_util as vvt
            import sys, time
            time.sleep(1)
            sys.exit( vvt.diff_exit_status )
            """[1:] )
        time.sleep(1)

        # run the test set but provide a false interruption
        vtu.interrupt_vvtest_run( '-n 2', count=1 )
        vrun = vtu.runvvtest( '-i' )
        cntD = vtu.parse_vvtest_counts( vrun.out )
        assert cntD['total'] == 4 and cntD['notrun'] > 0

        # restart with no keywords
        vtu.runvvtest( '-n 2' )
        vtu.runvvtest( '-i' ).assertCounts( total=4, npass=2, diff=1, fail=1 )

        # restart using results keyword
        vtu.interrupt_vvtest_run( '-n 2 -w', count=1 )
        vrun = vtu.runvvtest( '-i' )
        cntD = vtu.parse_vvtest_counts( vrun.out )
        assert cntD['total'] == 4 and cntD['notrun'] > 0

        vtu.runvvtest( '-n 2 -k notrun/notdone' )
        vtu.runvvtest( '-i' ).assertCounts( total=4, npass=2, diff=1, fail=1 )

        # none should restart now
        vtu.runvvtest( '-n 2' ).assertCounts( total=0 )

        # all of them should run again
        vrun = vtu.runvvtest( '-n 2 -R' )
        vrun.assertCounts( total=4, npass=2, diff=1, fail=1 )

    def test_prerun_file_cleanout_with_a_script_test(self):
        ""
        util.writescript( "clean.vvt", """
            #!/usr/bin/env python
            import os
            for f in os.listdir('.'):
                print ( 'existing file = '+f )
            assert not os.path.exists( 'generated_file.txt' )
            fp = open( 'generated_file.txt', 'w' )
            fp.write( 'gen file contents' )
            fp.close()
            """ )
        time.sleep(1)

        for batch in [False,True]:

            vtu.remove_results()

            vrun = vtu.runvvtest( batch=batch )
            vrun.assertCounts( total=1, npass=1 )

            assert len( glob.glob( 'TestResults*/clean/generated_file.txt' ) ) == 1

            # the generated file should be removed prior to running the script
            vrun = vtu.runvvtest( '-R', batch=batch )
            vrun.assertCounts( total=1, npass=1 )
            assert vrun.countGrepLogs( 'existing*generated' ) == 0

            # with -m option should fail because of "noclobber" in script
            vrun = vtu.runvvtest( '-R -m', batch=batch )
            vrun.assertCounts( total=1, fail=1 )
            assert vrun.countGrepLogs( 'existing*generated' ) == 1

    def test_prerun_file_cleanout_when_test_contains_a_soft_linked_directory(self):
        ""
        util.writefile( 'softdir.xml', """
            <rtest name="softdir">
              <link_files> subdir </link_files>
              <execute>
                ls subdir/afile.txt || exit 1
              </execute>
            </rtest>""" )
        util.writefile( 'subdir/afile.txt', """
            contents of file
            """ )
        time.sleep(1)

        for batch in [False,True]:

            vtu.remove_results()

            vrun = vtu.runvvtest( batch=batch )
            vrun.assertCounts( total=1, npass=1 )

            afile = util.globfile( 'TestResults*/softdir/subdir/afile.txt' )

            # run again exercises the pre-clean logic
            vrun = vtu.runvvtest( '-R', batch=batch )
            vrun.assertCounts( total=1, npass=1 )
            assert os.path.exists( afile )

            # now with post-clean (soft links are not cleaned)
            vrun = vtu.runvvtest( '-R -C', batch=batch )
            vrun.assertCounts( total=1, npass=1 )
            assert os.path.exists( afile )

    def test_a_previously_notrun_test_can_be_run_outside_of_TestResults(self):
        ""
        util.writefile( "testA.vvt", """
            raise Exception( 'fake exception' )
            """ )
        util.writefile( "testB.vvt", """
            #VVT: depends on : testA
            pass
            """ )
        time.sleep(1)

        vrun = vtu.runvvtest()
        vrun.assertCounts( total=2, fail=1, notrun=1 )

        util.writefile( 'testA.vvt', """
            pass
            """ )
        time.sleep(1)

        td = util.globfile( 'TestResults*/testA' )
        vrun = vtu.runvvtest( '-R', chdir=td )
        vrun.assertCounts( total=1, npass=1 )

        vrun = vtu.runvvtest()
        vrun.assertCounts( total=1, npass=1 )

    def magic_test_a_previously_notrun_test_can_be_run_inside_of_TestResults(self):
        ""
        util.writefile( "testA.vvt", """
            raise Exception( 'fake exception' )
            """ )
        util.writefile( "testB.vvt", """
            #VVT: depends on : testA
            pass
            """ )
        time.sleep(1)

        vrun = vtu.runvvtest()
        vrun.assertCounts( total=2, fail=1, notrun=1 )

        util.writefile( 'testA.vvt', """
            pass
            """ )
        time.sleep(1)

        td = util.globfile( 'TestResults*/testA' )
        vrun = vtu.runvvtest( '-R', chdir=td )
        vrun.assertCounts( total=1, npass=1 )

        td = util.globfile( 'TestResults*/testB' )
        vrun = vtu.runvvtest( chdir=td )
        vrun.assertCounts( total=1, npass=1 )


########################################################################

util.run_test_cases( sys.argv, sys.modules[__name__] )
